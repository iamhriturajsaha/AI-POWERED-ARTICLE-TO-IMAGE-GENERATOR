{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gz4elaGc8n0F"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "!pip install --quiet transformers diffusers accelerate safetensors sentencepiece streamlit pyngrok==7.0.0 pdfplumber python-docx bitsandbytes Pillow > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qyI-Z-oa9GdK"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os, time, tempfile, sys, io\n",
        "from pathlib import Path\n",
        "from textwrap import shorten\n",
        "from PIL import Image\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AKeEQ2Qn9K40"
      },
      "outputs": [],
      "source": [
        "# Model loading helper with fallback strategy\n",
        "from diffusers import DiffusionPipeline\n",
        "def try_load_sdxl(device):\n",
        "    \"\"\"Try loading SDXL base (best quality). If fails, raise.\"\"\"\n",
        "    model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "    print(\"Attempting to load SDXL base model (best quality). This can take ~20-60s on GPU...\")\n",
        "    pipe = DiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "    )\n",
        "    try:\n",
        "        pipe.enable_xformers_memory_efficient_attention()\n",
        "    except Exception as e:\n",
        "        print(\"xformers not available or failed to enable:\", e)\n",
        "    return pipe\n",
        "def try_load_sd2(device):\n",
        "    \"\"\"Fallback lightweight model (SD 2.1) for constrained runtimes.\"\"\"\n",
        "    model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
        "    print(\"Loading Stable Diffusion 2.1 Base (fallback).\")\n",
        "    pipe = DiffusionPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "    )\n",
        "    try:\n",
        "        pipe.enable_xformers_memory_efficient_attention()\n",
        "    except Exception:\n",
        "        pass\n",
        "    return pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "c045767f6cca4cf7874d74b6aea40e7c",
            "5a0aab989b474500a36055b73371f82e",
            "f3cb8793dabf444c8c06996293bed64e",
            "bc98ffd400f240cfad765e187e587696",
            "d9d7032c1d034133b72f681a6e99f687",
            "52af8bfb91314c4ebca0f93760888d2a",
            "7f5d290794804ed29d3b8c0bc5f87622",
            "772f4f2111ff4b77a9d22a2b91d75ac5",
            "18d6e434c82043f8a943bfadf603157b",
            "e97910bc2a56461c94ae9ae8ec86a354",
            "980d9f3d6f59485f9deab04a669526b5"
          ]
        },
        "id": "6f_aKSTL9OUY",
        "outputId": "9f30026d-db5a-4d04-beff-945c3a2428e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: False\n",
            "üîç Selecting image generation model...\n",
            "üü¢ Loading AbsoluteReality v1.8.1 (public, fast, realistic)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c045767f6cca4cf7874d74b6aea40e7c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö† No GPU available ‚Äî running on CPU (very slow).\n",
            "‚úÖ Loaded model: AbsoluteReality_v1.8.1  |  Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Load pipeline\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "# GPU Check\n",
        "def check_gpu():\n",
        "    gpu = torch.cuda.is_available()\n",
        "    if gpu:\n",
        "        try:\n",
        "            !nvidia-smi\n",
        "        except:\n",
        "            pass\n",
        "    return gpu\n",
        "GPU_AVAILABLE = check_gpu()\n",
        "print(\"GPU available:\", GPU_AVAILABLE)\n",
        "device = \"cuda\" if GPU_AVAILABLE else \"cpu\"\n",
        "pipe = None\n",
        "loaded_model_name = None\n",
        "print(\"üîç Selecting image generation model...\")\n",
        "# Public Model\n",
        "def try_load_absolute_reality():\n",
        "    print(\"üü¢ Loading AbsoluteReality v1.8.1 (public, fast, realistic)...\")\n",
        "    return DiffusionPipeline.from_pretrained(\n",
        "        \"digiplay/AbsoluteReality_v1.8.1\",\n",
        "        torch_dtype=torch.float16 if GPU_AVAILABLE else torch.float32,\n",
        "        use_safetensors=True\n",
        "    )\n",
        "# Load Model\n",
        "try:\n",
        "    pipe = try_load_absolute_reality()\n",
        "    loaded_model_name = \"AbsoluteReality_v1.8.1\"\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Failed to load AbsoluteReality:\", e)\n",
        "    raise RuntimeError(\"üö´ No image generation model could be loaded.\")\n",
        "# Move Model To GPU\n",
        "if GPU_AVAILABLE:\n",
        "    try:\n",
        "        pipe = pipe.to(\"cuda\")\n",
        "        print(\"üöÄ Model moved to GPU successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è GPU move failed:\", e)\n",
        "        print(\"‚û° Keeping model on CPU (slower).\")\n",
        "else:\n",
        "    print(\"‚ö† No GPU available ‚Äî running on CPU (very slow).\")\n",
        "print(f\"‚úÖ Loaded model: {loaded_model_name}  |  Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization and character-extraction model\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "SUM_MODEL = \"google/flan-t5-base\"\n",
        "print(\"Loading summarization model:\", SUM_MODEL)\n",
        "tok = AutoTokenizer.from_pretrained(SUM_MODEL)\n",
        "model_summ = AutoModelForSeq2SeqLM.from_pretrained(SUM_MODEL).to(device if device==\"cuda\" else \"cpu\")\n",
        "print(\"Summarization model loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doW4EzfYwMMq",
        "outputId": "0cf544c6-36d3-4d2f-81e1-554e0b72de84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading summarization model: google/flan-t5-base\n",
            "Summarization model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text extraction helpers (txt, pdf, docx)\n",
        "import pdfplumber, docx\n",
        "def extract_text_from_uploaded(file_obj, filename):\n",
        "    \"\"\"file_obj: BytesIO or UploadedFile-like; filename: name with extension\"\"\"\n",
        "    ext = filename.split(\".\")[-1].lower()\n",
        "    if ext == \"txt\":\n",
        "        data = file_obj.read()\n",
        "        if isinstance(data, bytes):\n",
        "            return data.decode(errors=\"ignore\")\n",
        "        return str(data)\n",
        "    elif ext == \"pdf\":\n",
        "        with pdfplumber.open(file_obj) as pdf:\n",
        "            pages = []\n",
        "            for p in pdf.pages:\n",
        "                text = p.extract_text()\n",
        "                if text:\n",
        "                    pages.append(text)\n",
        "            return \"\\n\\n\".join(pages)\n",
        "    elif ext == \"docx\":\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".docx\")\n",
        "        tmp.write(file_obj.read())\n",
        "        tmp.flush(); tmp.close()\n",
        "        doc = docx.Document(tmp.name)\n",
        "        paragraphs = [p.text for p in doc.paragraphs if p.text.strip() != \"\"]\n",
        "        os.unlink(tmp.name)\n",
        "        return \"\\n\\n\".join(paragraphs)\n",
        "    else:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "L4iXHKe7xFd9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize & extract characters\n",
        "def summarize_article(text, max_length=200):\n",
        "    prompt = f\"Summarize the following article into 5 concise scene descriptions (short sentences). Keep each scene to one line:\\n\\n{text}\"\n",
        "    inputs = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model_summ.device)\n",
        "    outputs = model_summ.generate(**inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
        "    summary = tok.decode(outputs[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "def extract_characters(text):\n",
        "    prompt = f\"Extract the main characters from the article and give 1-2 short physical descriptors and roles (e.g., 'young woman, determined activist') as a comma-separated list:\\n\\n{text}\"\n",
        "    inputs = tok(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model_summ.device)\n",
        "    outputs = model_summ.generate(**inputs, max_length=150, num_beams=3, early_stopping=True)\n",
        "    chars = tok.decode(outputs[0], skip_special_tokens=True)\n",
        "    return chars\n",
        "# Prompt builder - create cinematic, high-detail prompts with face consistency hinting\n",
        "def build_prompts_from_summary(summary_text, characters, max_frames=6):\n",
        "    scenes = []\n",
        "    if \"\\n\" in summary_text:\n",
        "        cand = [s.strip() for s in summary_text.split(\"\\n\") if s.strip()]\n",
        "    else:\n",
        "        cand = [s.strip() for s in summary_text.split(\".\") if s.strip()]\n",
        "    for s in cand:\n",
        "        if len(s) >= 20:\n",
        "            scenes.append(s)\n",
        "        if len(scenes) >= max_frames:\n",
        "            break\n",
        "    if not scenes:\n",
        "        scenes = [shorten(summary_text, width=120)]\n",
        "    prompts = []\n",
        "    for idx, scene in enumerate(scenes):\n",
        "        prompt = (\n",
        "            f\"Ultra-detailed photorealistic photograph. {scene}. \"\n",
        "            f\"Include characters: {characters}. \"\n",
        "            \"Cinematic framing, filmic lighting, shallow depth of field, ultra sharp details, 8k photographic realism, award-winning photo, realistic skin tones, natural shadows.\"\n",
        "        )\n",
        "        prompts.append(prompt)\n",
        "    return prompts"
      ],
      "metadata": {
        "id": "s-oauTExxH8V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image generation wrapper with safety and fallback\n",
        "import os\n",
        "BASE_SAVE_DIR = \"/content/drive/MyDrive/Article_Image_Generator\"\n",
        "os.makedirs(BASE_SAVE_DIR, exist_ok=True)\n",
        "from PIL import Image\n",
        "def generate_images_for_prompts(prompts, article_name=\"article\", width=1024, height=1024, steps=28, save_dir=BASE_SAVE_DIR):\n",
        "    out_paths = []\n",
        "    safe_save_dir = os.path.join(save_dir, article_name.replace(\" \", \"_\"))\n",
        "    os.makedirs(safe_save_dir, exist_ok=True)\n",
        "    for i, p in enumerate(prompts):\n",
        "        try:\n",
        "            if device == \"cuda\":\n",
        "                img = pipe(prompt=p, height=height, width=width, num_inference_steps=steps).images[0]\n",
        "            else:\n",
        "                print(\"Warning: Generating on CPU. This will be slow.\")\n",
        "                img = pipe(prompt=p, height=768, width=768, num_inference_steps=20).images[0]\n",
        "            filename = os.path.join(safe_save_dir, f\"frame_{i+1}.png\")\n",
        "            img.save(filename)\n",
        "            out_paths.append(filename)\n",
        "            print(f\"Saved {filename}\")\n",
        "        except Exception as e:\n",
        "            print(\"Image generation error for prompt:\", e)\n",
        "            try:\n",
        "                img = pipe(prompt=p, height=768, width=768, num_inference_steps=18).images[0]\n",
        "                filename = os.path.join(safe_save_dir, f\"frame_{i+1}_fallback.png\")\n",
        "                img.save(filename)\n",
        "                out_paths.append(filename)\n",
        "            except Exception as e2:\n",
        "                print(\"Fallback generation failed:\", e2)\n",
        "    return out_paths"
      ],
      "metadata": {
        "id": "nMarcpYxxKhN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit Backend\n",
        "MAIN_PY = r\"\"\"\n",
        "import os\n",
        "import io\n",
        "import tempfile\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from PIL import Image, ImageFilter, ImageOps\n",
        "import torch\n",
        "# ============================================================\n",
        "# CONFIG (Optimized for SPEED + Realism)\n",
        "# ============================================================\n",
        "BASE_SAVE_DIR = \"/content/drive/MyDrive/Article_Image_Generator\"\n",
        "os.makedirs(BASE_SAVE_DIR, exist_ok=True)\n",
        "SUM_MODEL = \"google/flan-t5-base\"\n",
        "N_CANDIDATES = 1          # ‚ö° FASTEST: only 1 image per prompt\n",
        "IMG_HEIGHT = 640          # ‚ö° lower res = faster\n",
        "IMG_WIDTH = 640\n",
        "SAMPLER_STEPS = 18        # ‚ö° reduced steps (still good quality)\n",
        "CFG_SCALE = 7.0           # balanced\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "STYLE = (\n",
        "    \"photorealistic, ultra-detailed, cinematic lighting, natural skin tones, \"\n",
        "    \"film grain, 85mm lens, depth of field, award-winning photography\"\n",
        ")\n",
        "NEGATIVE = (\n",
        "    \"lowres, blurry, deformed face, extra limbs, watermark, text, artifacts, bad anatomy\"\n",
        ")\n",
        "# ============================================================\n",
        "# TEXT EXTRACTION\n",
        "# ============================================================\n",
        "try: import pdfplumber\n",
        "except: pdfplumber = None\n",
        "try: import docx\n",
        "except: docx = None\n",
        "def extract_text_from_uploaded(file_obj, filename):\n",
        "    ext = filename.split(\".\")[-1].lower()\n",
        "    file_obj.seek(0)\n",
        "    if ext == \"txt\":\n",
        "        data = file_obj.read()\n",
        "        return data.decode(errors=\"ignore\") if isinstance(data, bytes) else str(data)\n",
        "    if ext == \"pdf\" and pdfplumber:\n",
        "        try:\n",
        "            with pdfplumber.open(file_obj) as pdf:\n",
        "                pages = [p.extract_text() or \"\" for p in pdf.pages]\n",
        "            return \"\\n\\n\".join(pages)\n",
        "        except:\n",
        "            return \"\"\n",
        "    if ext == \"docx\" and docx:\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".docx\")\n",
        "        tmp.write(file_obj.read()); tmp.close()\n",
        "        d = docx.Document(tmp.name)\n",
        "        os.unlink(tmp.name)\n",
        "        return \"\\n\".join([p.text for p in d.paragraphs])\n",
        "    return \"\"\n",
        "# ============================================================\n",
        "# SUMMARIZATION\n",
        "# ============================================================\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "_tok = None\n",
        "_summ = None\n",
        "def _ensure_summarizer():\n",
        "    global _tok, _summ\n",
        "    if _tok is None:\n",
        "        _tok = AutoTokenizer.from_pretrained(SUM_MODEL)\n",
        "    if _summ is None:\n",
        "        _summ = AutoModelForSeq2SeqLM.from_pretrained(SUM_MODEL).to(DEVICE)\n",
        "def summarize_article(text, max_scenes=6):\n",
        "    _ensure_summarizer()\n",
        "    prompt = f\"Summarize into {max_scenes} cinematic scenes:\\n{text}\"\n",
        "    inp = _tok(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(DEVICE)\n",
        "    out = _summ.generate(inp.input_ids, max_length=256, num_beams=4)\n",
        "    summary = _tok.decode(out[0], skip_special_tokens=True)\n",
        "    lines = [l.strip() for l in summary.split(\"\\n\") if l.strip()]\n",
        "    return \"\\n\".join(lines[:max_scenes])\n",
        "def extract_characters(text):\n",
        "    _ensure_summarizer()\n",
        "    prompt = \"List main characters with 1‚Äì2 word physical descriptors:\\n\" + text\n",
        "    inp = _tok(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(DEVICE)\n",
        "    out = _summ.generate(inp.input_ids, max_length=80, num_beams=3)\n",
        "    chars = _tok.decode(out[0], skip_special_tokens=True)\n",
        "    return chars.replace(\"\\n\", \" \").strip()\n",
        "# ============================================================\n",
        "# PROMPT BUILDER\n",
        "# ============================================================\n",
        "def build_prompts_from_summary(summary, characters, max_frames=6):\n",
        "    lines = [l.strip() for l in summary.split(\"\\n\") if l.strip()][:max_frames]\n",
        "    return [f\"{l}. Characters: {characters}. {STYLE}\" for l in lines]\n",
        "# ============================================================\n",
        "# MODEL LOADING (Optimized for speed)\n",
        "# ============================================================\n",
        "from diffusers import DiffusionPipeline\n",
        "_pipe = None\n",
        "def _load_model_fast():\n",
        "    global _pipe\n",
        "    models = [\n",
        "        \"Lykon/dreamshaper-xl-1.0\",     # ‚ö° fastest realistic\n",
        "        \"digiplay/AbsoluteReality_v1.8.1\",\n",
        "    ]\n",
        "    dtype = torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
        "    for m in models:\n",
        "        try:\n",
        "            print(\"Loading ‚Üí\", m)\n",
        "            _pipe = DiffusionPipeline.from_pretrained(m, torch_dtype=dtype)\n",
        "            _pipe.to(DEVICE)\n",
        "            print(\"Loaded:\", m)\n",
        "            return\n",
        "        except Exception as e:\n",
        "            print(\"FAILED:\", m, \"‚Üí\", e)\n",
        "    raise RuntimeError(\"No model could be loaded.\")\n",
        "def get_pipe():\n",
        "    global _pipe\n",
        "    if _pipe is None:\n",
        "        _load_model_fast()\n",
        "    return _pipe\n",
        "# ============================================================\n",
        "# SIMPLE SHARPENING\n",
        "# ============================================================\n",
        "def enhance(img):\n",
        "    try:\n",
        "        img = img.filter(ImageFilter.UnsharpMask(radius=0.8, percent=110))\n",
        "    except:\n",
        "        pass\n",
        "    return img\n",
        "# ============================================================\n",
        "# IMAGE GENERATION (FAST)\n",
        "# ============================================================\n",
        "def generate_high_realism_images_from_prompts(prompts, article_name=\"article\"):\n",
        "    pipe = get_pipe()\n",
        "    save_dir = os.path.join(BASE_SAVE_DIR, article_name.replace(\" \", \"_\"))\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    out_paths = []\n",
        "    for i, p in enumerate(prompts):\n",
        "        gen = torch.Generator(DEVICE).manual_seed(torch.randint(0, 999999999, (1,)).item())\n",
        "        img = pipe(\n",
        "            prompt=p,\n",
        "            negative_prompt=NEGATIVE,\n",
        "            height=IMG_HEIGHT,\n",
        "            width=IMG_WIDTH,\n",
        "            guidance_scale=CFG_SCALE,\n",
        "            num_inference_steps=SAMPLER_STEPS,\n",
        "            generator=gen\n",
        "        ).images[0]\n",
        "        img = enhance(img)\n",
        "        out = os.path.join(save_dir, f\"scene_{i+1}.png\")\n",
        "        img.save(out)\n",
        "        out_paths.append(out)\n",
        "    return out_paths\n",
        "def generate_images_for_prompts(prompts, article_name):\n",
        "    return generate_high_realism_images_from_prompts(prompts, article_name)\n",
        "\"\"\"\n",
        "with open(\"main.py\", \"w\") as f:\n",
        "    f.write(MAIN_PY)\n",
        "print(\"‚ö° main.py (FAST VERSION) created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF_wcnMP8BZ-",
        "outputId": "571a87a4-5523-4757-da7f-de88e0eb2b06"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö° main.py (FAST VERSION) created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit UI\n",
        "STREAMLIT_APP = r'''\n",
        "import streamlit as st\n",
        "import os\n",
        "# -------------------------------\n",
        "# Custom Glassmorphism CSS\n",
        "# -------------------------------\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "body {\n",
        "    background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);\n",
        "    color: #ffffff !important;\n",
        "}\n",
        ".main, .block-container {\n",
        "    background: transparent !important;\n",
        "}\n",
        ".block-container {\n",
        "    backdrop-filter: blur(12px);\n",
        "    -webkit-backdrop-filter: blur(12px);\n",
        "    background: rgba(255,255,255,0.08) !important;\n",
        "    padding: 35px 35px;\n",
        "    border-radius: 16px;\n",
        "    border: 1px solid rgba(255,255,255,0.18);\n",
        "    margin-top: 30px;\n",
        "}\n",
        "h1, h2, h3, h4, h5 {\n",
        "    color: #e8f1f2 !important;\n",
        "    font-weight: 700;\n",
        "    text-shadow: 0 1px 3px rgba(0,0,0,0.25);\n",
        "}\n",
        ".stRadio > label {\n",
        "    color: white !important;\n",
        "}\n",
        ".stButton>button {\n",
        "    background: linear-gradient(90deg, #ff7eb3, #ff758c);\n",
        "    color: white !important;\n",
        "    border-radius: 12px;\n",
        "    padding: 0.65rem 1.3rem;\n",
        "    font-size: 1rem;\n",
        "    border: none;\n",
        "    font-weight: 600;\n",
        "    transition: 0.25s ease;\n",
        "}\n",
        ".stButton>button:hover {\n",
        "    background: linear-gradient(90deg, #ff9eb9, #ff8aa7);\n",
        "    transform: scale(1.05);\n",
        "}\n",
        ".stFileUploader label {\n",
        "    color: #ffffff !important;\n",
        "    font-size: 1.05rem !important;\n",
        "}\n",
        "hr {\n",
        "    border: 1px solid rgba(255,255,255,0.25);\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "# -------------------------------\n",
        "# Title + Description\n",
        "# -------------------------------\n",
        "st.title(\"üåå AI Article ‚Üí Realistic Image Generator\")\n",
        "st.markdown(\"#### Convert entire articles into stunning cinematic images using AI üéûÔ∏è‚ú®\")\n",
        "st.markdown(\"---\")\n",
        "# -------------------------------\n",
        "# Import backend functions\n",
        "# -------------------------------\n",
        "from main import (\n",
        "    extract_text_from_uploaded,\n",
        "    summarize_article,\n",
        "    extract_characters,\n",
        "    build_prompts_from_summary,\n",
        "    generate_images_for_prompts\n",
        ")\n",
        "# -------------------------------\n",
        "# UI Mode Selection\n",
        "# -------------------------------\n",
        "mode = st.radio(\"Select Mode\", [\"üéØ Single Article\", \"üìö Batch Processing\"])\n",
        "# ====================================================================\n",
        "# SINGLE ARTICLE MODE\n",
        "# ====================================================================\n",
        "if mode == \"üéØ Single Article\":\n",
        "    file = st.file_uploader(\"üìÑ Upload an Article File\", type=[\"txt\",\"pdf\",\"docx\"])\n",
        "    if file:\n",
        "        with st.spinner(\"üìò Reading file...\"):\n",
        "            text = extract_text_from_uploaded(file, file.name)\n",
        "        st.subheader(\"üìù Article Preview\")\n",
        "        st.write(text[:1000] + (\"...\" if len(text) > 1000 else \"\"))\n",
        "        st.markdown(\"---\")\n",
        "        if st.button(\"üöÄ Generate Cinematic Images\"):\n",
        "            with st.spinner(\"üß† Understanding & summarizing article...\"):\n",
        "                summary = summarize_article(text)\n",
        "                characters = extract_characters(text)\n",
        "                prompts = build_prompts_from_summary(summary, characters)\n",
        "            st.subheader(\"üé¨ Generated Prompts\")\n",
        "            for i, p in enumerate(prompts):\n",
        "                st.markdown(f\"**Scene {i+1}:** {p}\")\n",
        "            st.markdown(\"---\")\n",
        "            with st.spinner(\"üé® Creating high-quality realistic images...\"):\n",
        "                images = generate_images_for_prompts(prompts, article_name=file.name.split('.')[0])\n",
        "            st.success(\"‚ú® Image Generation Complete!\")\n",
        "            for img in images:\n",
        "                st.image(img, width=450)\n",
        "# ====================================================================\n",
        "# BATCH MODE\n",
        "# ====================================================================\n",
        "else:\n",
        "    files = st.file_uploader(\"üìÑ Upload Multiple Article Files\", type=[\"txt\",\"pdf\",\"docx\"], accept_multiple_files=True)\n",
        "    if files and st.button(\"üöÄ Process All Files\"):\n",
        "        for file in files:\n",
        "            st.write(f\"üìÇ Processing **{file.name}**...\")\n",
        "            text = extract_text_from_uploaded(file, file.name)\n",
        "            summary = summarize_article(text)\n",
        "            characters = extract_characters(text)\n",
        "            prompts = build_prompts_from_summary(summary, characters)\n",
        "            images = generate_images_for_prompts(prompts, article_name=file.name.split('.')[0])\n",
        "            st.success(f\"‚úî Finished {file.name}, generated {len(images)} images.\")\n",
        "        st.success(\"üéâ Batch Processing Complete! Images saved to Google Drive.\")\n",
        "'''\n",
        "# Write Streamlit UI to app.py\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(STREAMLIT_APP)\n",
        "print(\"app.py created successfully with refined glass UI.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7JB4O9gxO5d",
        "outputId": "a99be987-2ab4-4b07-d8d8-6c5194ebaffe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py created successfully with refined glass UI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inject the real functions into the main.py module so Streamlit can import them\n",
        "import types\n",
        "import sys\n",
        "# Create a dynamic module named \"main\"\n",
        "main_mod = types.ModuleType(\"main\")\n",
        "# Assign actual functions & variables from notebook\n",
        "main_mod.extract_text_from_uploaded = extract_text_from_uploaded\n",
        "main_mod.summarize_article = summarize_article\n",
        "main_mod.extract_characters = extract_characters\n",
        "main_mod.build_prompts_from_summary = build_prompts_from_summary\n",
        "main_mod.generate_images_for_prompts = generate_images_for_prompts\n",
        "main_mod.BASE_SAVE_DIR = BASE_SAVE_DIR\n",
        "# Register the module so that `from main import *` works inside Streamlit\n",
        "sys.modules[\"main\"] = main_mod\n",
        "print(\"‚úÖ Successfully injected notebook functions into 'main' module.\")\n",
        "print(\"üéâ Streamlit app is now ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFH8rF_5xW52",
        "outputId": "cacc3ede-b0a9-4835-a8dd-bd9b7f2d7e8a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Successfully injected notebook functions into 'main' module.\n",
            "üéâ Streamlit app is now ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit App Deployment\n",
        "!pip install -q streamlit pyngrok\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import logging\n",
        "logging.getLogger(\"pyngrok.process\").setLevel(logging.ERROR)\n",
        "# Configure Ngrok Token\n",
        "NGROK_AUTH_TOKEN = \"2z0Oqv0tD166fELGCHwV2gLZwq1_2G2zUQRSs6C27k9vdzxwq\"\n",
        "conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
        "# Prepare log directory\n",
        "LOG_DIR = \"/content/logs\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "# Clean any running instance\n",
        "!pkill -f streamlit 2>/dev/null || true\n",
        "ngrok.kill()\n",
        "print(\"‚öôÔ∏è Starting Streamlit...\")\n",
        "# Launch Streamlit server\n",
        "streamlit_cmd = [\n",
        "    \"streamlit\", \"run\", \"app.py\",\n",
        "    \"--server.port\", \"8501\",\n",
        "    \"--server.address\", \"0.0.0.0\"\n",
        "]\n",
        "log_file_path = f\"{LOG_DIR}/app_log.txt\"\n",
        "with open(log_file_path, \"w\") as log_file:\n",
        "    process = subprocess.Popen(\n",
        "        streamlit_cmd,\n",
        "        stdout=log_file,\n",
        "        stderr=log_file,\n",
        "        text=True\n",
        "    )\n",
        "time.sleep(8)\n",
        "# Create Ngrok tunnel\n",
        "public_url = ngrok.connect(addr=8501)\n",
        "print(\"üöÄ Your Streamlit app is live at:\", public_url)\n",
        "print(\"üìú Logs at:\", log_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxcfvHS0xa02",
        "outputId": "e828d11d-2882-499a-971f-02d8c74b4716"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "‚öôÔ∏è Starting Streamlit...\n",
            "üöÄ Your Streamlit app is live at: NgrokTunnel: \"https://d7fc55052b38.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "üìú Logs at: /content/logs/app_log.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c045767f6cca4cf7874d74b6aea40e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a0aab989b474500a36055b73371f82e",
              "IPY_MODEL_f3cb8793dabf444c8c06996293bed64e",
              "IPY_MODEL_bc98ffd400f240cfad765e187e587696"
            ],
            "layout": "IPY_MODEL_d9d7032c1d034133b72f681a6e99f687"
          }
        },
        "5a0aab989b474500a36055b73371f82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52af8bfb91314c4ebca0f93760888d2a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7f5d290794804ed29d3b8c0bc5f87622",
            "value": "Loading‚Äápipeline‚Äácomponents...:‚Äá100%"
          }
        },
        "f3cb8793dabf444c8c06996293bed64e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772f4f2111ff4b77a9d22a2b91d75ac5",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18d6e434c82043f8a943bfadf603157b",
            "value": 6
          }
        },
        "bc98ffd400f240cfad765e187e587696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e97910bc2a56461c94ae9ae8ec86a354",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_980d9f3d6f59485f9deab04a669526b5",
            "value": "‚Äá6/6‚Äá[00:02&lt;00:00,‚Äá‚Äá2.90it/s]"
          }
        },
        "d9d7032c1d034133b72f681a6e99f687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52af8bfb91314c4ebca0f93760888d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5d290794804ed29d3b8c0bc5f87622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "772f4f2111ff4b77a9d22a2b91d75ac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d6e434c82043f8a943bfadf603157b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e97910bc2a56461c94ae9ae8ec86a354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980d9f3d6f59485f9deab04a669526b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}